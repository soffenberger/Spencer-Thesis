This validation study revealed the instrument could be used to evaluate cybersecurity but would benefit from minor modifications. The \gls{cci} has many good properties: high reliability and strong expert consensus on the suitability of all items. Unfortunately, our findings revealed a few weaknesses of the \gls{cci} as currently constructed: low reliability for individual concepts, items that are too difficult, and too many difficult items on the instrument.

From the results of the pilot trial, the \gls{cci} had very high reliability, especially when compared to other \glspl{cilabel}. The Cronbach's $\alpha$ is 0.78, which is considered good for a \gls{cilabel}. In addition to the \gls{cci} reliability, no items decrease the overall $\alpha$. Not reducing the $\alpha$ indicates the individual items are all measuring the same construct of cybersecurity conceptual knowledge \cite{dlci}. The reliability of the instrument is necessary for the instrument to be valid but not sufficient.

Experts positively reviewed each item and provided feedback to improve the items. Experts also provided suggestions for improving the wording and distractors of each item. We used this feedback to select the 25 items that had the strongest consensus of quality from the experts. The expert reviews provide evidence for the content validity of the \gls{cci} by demonstrating that multiple cybersecurity instructors believe that the \gls{cci} items represent conceptual knowledge that students should have after a first course in cybersecurity. 

\glsreset{c}

The strengths of the \gls{cci} indicate that the collection of items and individual items are well designed from an instructor perspective and reliable from a student performance perspective. However, the student response data reveals that there is still room for improvement. Notably, while we designed the \gls{cci} to assess five concepts, the student performance data did not align well with these five concepts. For example, there is no consistent correlation of the items within each concept subtest. Additionally, the items that constitute a subtest have low reliability; each $\alpha$ for the individual concept subtest is below 0.50 \cite{jorian}. Because of the low reliability of the concept subtests, we cannot recommend using the concept subtests to assess students' knowledge of each concept individually.

There are two possible interpretations for this lack of correlation and reliability within the concept subtests. First, it is possible that the items were poorly designed and do not reflect the core concepts. Second, it is possible that the concepts themselves are poorly bounded, interconnected, or too complex. Given that the expert reviewers did not express any concerns about the content of the items, we argue that the second interpretation is more likely. 

Our finding of low cohesion among concept subtests is a common finding among previously published \glspl{cilabel} \cite{jorian}. The commonality of this finding suggests that it is generally difficult for designers of an instrument to design effective concept subtests. While most items may primarily engage students in one concept, the concepts are likely interconnected. Students need to use multiple concepts to answer each item correctly. We believe that this fact may be especially true in cybersecurity, which requires individuals to consider the motivations or capabilities of attackers, constraints or goals of defenders, and the technologies or techniques needed to mitigate risk.

Additionally, the concepts discovered in the Delphi process may be too complex and are really culminations of similar, but separate, concepts \cite{delphi}. For example, concept \gls{c} involves four unique forms of attack. A confidentiality attack could cover attacking a secure message protocol. An availability attack could cover a denial of service attack. Both of these examples are forms of attack and both of them are very relevant to cybersecurity. A student, however, may understand mechanisms that enable secure communications and still have very little idea about denial-of-service attacks. Thus each item of the \gls{cci} must be multifaceted and creating subtests will be difficult, if not intractable, without creating isomorphic, redundant questions.


%In future iterations, it may be useful to split these concepts up into smaller concepts or use heuristics. \gls{efa} can find underlying relations between exam constructs. These heuristics will be useful with more students to explore potential concept groupings.

If we want to create reliable and valid concept subtests, we may need to consider other models for creating them. For example, we could try narrowing the scope of concept \gls{c} to just one attribute (e.g., confidentiality). This option may not be desirable because it ignores the complexity of an attacker's varied motivations. Alternatively, we could create multiple instruments that more fully explore each of the five core concepts, but this option would dramatically increase the work and cost of creating instruments for cybersecurity. As currently constructed, the \gls{cci} provides a reliable instrument for measuring a students' overall understanding of cybersecurity, which is a much-needed first step. Future work can explore which types of future development are needed for creating these subtests.

Unlike the alignment of the concepts, a good range of difficulty is often achieved in published \glspl{cilabel} and necessary for the instrument to be valid. The \gls{cci} is skewed to be too difficult: five items are more difficult than the recommended level of difficulty, and for 21 out of 25 items, fewer than 50\% of students answered each item correctly. This degree of difficulty suggests that some items need to be made easier to improve our ability to distinguish between students with varying abilities and knowledge. Future work on the \gls{cci} must explore how to effectively make some items easier to improve the quality of the \gls{cci}.  

\section{Limitations}

There are a number of limitations in the pilot trial. The most notable limitation is the depth of analysis performed on the pilot trial results. \gls{irt} is not practical with the number of students in the trial but would enable deeper analysis. Additionally, because the Cronbach's $\alpha$ for each concept subtest was so low, we did not perform measurements such as \gls{cfa} and \gls{efa}.  These limitations are acceptable because this study is a pilot test.


There were also limitations in the number of students from each university. Ideally, there would be a similar number of representatives from the different types of universities so that the results were not skewed toward University A. The localization may have biased the findings to one university.

\section{Future Work}

We will take Q15 as a specific example of the type of modification we will make to the difficult items. Less than 10\% of students answered Q15 correctly, far below what is acceptable for a \gls{cilabel}. \glsreset{v}

The item covers finding vulnerabilities in a defense and falls under concept \gls{v}. The scenario describes a hypothetical nuclear treaty between two countries that requires a method of securely transmitting a message from a monitoring device. Neither country trusts the other, and the design must be fair to each country. There are certain properties the solution must hold. Both parties want assurances that the message is not modified. Country A wants to ensure that the message originates from the device. Country B wants to monitor the message data in real time. The premise is: ``The sender applies a keyed cryptographic hash function to each message using a key distributed only to the sender, Country A, and Country B." Students are expected to find potential vulnerabilities in the suggested outputs of the device.

Option A is the message with a hash of the message and the current time. Options B, C, and D are the key and a hash of the message, the message, and hash of the message, and the hash of the message respectively. Option E, the correct answer, is that the design cannot satisfy the system requirements. 

Our distractor analysis revealed that the best students chose Option A more than the correct answer. This finding reveals that, as students' knowledge increased, this wrong answer became more compelling. When constructed well, each item should lead students to pick the correct answer more often as their knowledge increases.

The preference for Option A is understandable given that it is more reasonable than the other 3 options. Options B and D do not even send the original message so the message cannot be verified. Option A and Option C do not guarantee that the source is sending the message and since each party has the key they can modify the message and attach a new hash. Because A has the same structure as C with the addition of time being sent, it appears to be strictly superior to C making it the best option. Students must see the problems with each option and select Option E which serves as a ``none of the above." Including a ``none of the above" in general makes assessments harder \cite{none_of_above}, especially with Option A and C satisfying some of the desired properties. 

The problem with the item, and further ``none of the above" in general, is that Option E makes no assertion. This fact leads students to pick the most reasonable of the other choices. We have modified this item, changing Option E to make an assertion. The new Option E is ``The design does not work because Countries A and B can modify the message." This allows students a definitive assertion to test and come to the same conclusion that the other options do not satisfy the requirements. We anticipate that this change, while being minor, will make the item easier and differentiate more students.

After making similar modifications to other items, our next work is to administer the instrument to more students and reanalyze the results. With the easier items, the difficulty will cover a better range and better separate students. The range of difficulties and modification of items that are too difficult should increase the discriminatory power of the \gls{cci} and improve the \gls{cci}'s validity and usefulness.
